#!/usr/bin/env python3
"""
Script de sauvegarde automatique de la base de donnÃ©es PostgreSQL vers DigitalOcean Spaces.

Ce script :
1. Effectue un dump de la base de donnÃ©es PostgreSQL
2. Compresse le fichier avec gzip
3. Upload vers DigitalOcean Spaces dans backups/database/YYYY/MM/DD/
4. Supprime les backups de plus de 30 jours

ConÃ§u pour Ãªtre exÃ©cutÃ© via cron toutes les heures.
"""

import os
import sys
import subprocess
import gzip
import boto3
from datetime import datetime, timedelta
from pathlib import Path

# Ajouter le rÃ©pertoire parent au path pour importer app
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def get_database_url():
    """RÃ©cupÃ¨re l'URL de la base de donnÃ©es depuis les variables d'environnement."""
    db_url = os.environ.get('DATABASE_URL')
    if not db_url:
        print("âŒ Erreur: DATABASE_URL non dÃ©fini")
        sys.exit(1)
    return db_url

def get_spaces_config():
    """RÃ©cupÃ¨re la configuration DigitalOcean Spaces."""
    config = {
        'key': os.environ.get('DIGITALOCEAN_SPACES_KEY'),
        'secret': os.environ.get('DIGITALOCEAN_SPACES_SECRET'),
        'endpoint': os.environ.get('DIGITALOCEAN_SPACES_ENDPOINT', 'https://fra1.digitaloceanspaces.com'),
        'bucket': os.environ.get('DIGITALOCEAN_SPACES_BUCKET', 'atlas-storage')
    }

    if not config['key'] or not config['secret']:
        print("âŒ Erreur: ClÃ©s DigitalOcean Spaces non dÃ©finies")
        sys.exit(1)

    return config

def create_database_backup():
    """CrÃ©e un backup de la base de donnÃ©es avec pg_dump."""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_filename = f"atlas_backup_{timestamp}.sql"
    backup_path = f"/tmp/{backup_filename}"

    print(f"ğŸ“¦ CrÃ©ation du backup: {backup_filename}")

    # Extraire les infos de connexion depuis DATABASE_URL
    db_url = get_database_url()

    try:
        # pg_dump avec connexion depuis DATABASE_URL
        result = subprocess.run(
            ['pg_dump', db_url, '-f', backup_path],
            capture_output=True,
            text=True,
            timeout=3600  # 1 heure max
        )

        if result.returncode != 0:
            print(f"âŒ Erreur pg_dump: {result.stderr}")
            return None

        print(f"âœ… Backup SQL crÃ©Ã©: {os.path.getsize(backup_path) / (1024*1024):.2f} MB")
        return backup_path

    except subprocess.TimeoutExpired:
        print("âŒ Timeout lors du backup (> 1h)")
        return None
    except Exception as e:
        print(f"âŒ Erreur lors du backup: {e}")
        return None

def compress_backup(backup_path):
    """Compresse le backup avec gzip."""
    compressed_path = f"{backup_path}.gz"

    print(f"ğŸ—œï¸  Compression du backup...")

    try:
        with open(backup_path, 'rb') as f_in:
            with gzip.open(compressed_path, 'wb', compresslevel=9) as f_out:
                f_out.writelines(f_in)

        # Supprimer le fichier non compressÃ©
        os.remove(backup_path)

        compressed_size = os.path.getsize(compressed_path) / (1024*1024)
        print(f"âœ… Backup compressÃ©: {compressed_size:.2f} MB")

        return compressed_path

    except Exception as e:
        print(f"âŒ Erreur lors de la compression: {e}")
        return None

def upload_to_spaces(file_path):
    """Upload le backup vers DigitalOcean Spaces."""
    config = get_spaces_config()

    # CrÃ©er le chemin dans Spaces: backups/database/YYYY/MM/DD/filename
    now = datetime.now()
    spaces_key = f"backups/database/{now.year}/{now.month:02d}/{now.day:02d}/{os.path.basename(file_path)}"

    print(f"â˜ï¸  Upload vers Spaces: {spaces_key}")

    try:
        # Initialiser le client S3 (compatible avec Spaces)
        s3_client = boto3.client(
            's3',
            endpoint_url=config['endpoint'],
            aws_access_key_id=config['key'],
            aws_secret_access_key=config['secret']
        )

        # Upload avec metadata
        s3_client.upload_file(
            file_path,
            config['bucket'],
            spaces_key,
            ExtraArgs={
                'ACL': 'private',
                'Metadata': {
                    'backup-date': now.isoformat(),
                    'database': 'atlas_production',
                    'type': 'postgresql_dump'
                }
            }
        )

        # Supprimer le fichier local
        os.remove(file_path)

        print(f"âœ… Backup uploadÃ© avec succÃ¨s")
        return spaces_key

    except Exception as e:
        print(f"âŒ Erreur lors de l'upload: {e}")
        return None

def cleanup_old_backups():
    """Supprime les backups de plus de 30 jours."""
    config = get_spaces_config()
    retention_days = 30
    cutoff_date = datetime.now() - timedelta(days=retention_days)

    print(f"ğŸ§¹ Nettoyage des backups > {retention_days} jours...")

    try:
        s3_client = boto3.client(
            's3',
            endpoint_url=config['endpoint'],
            aws_access_key_id=config['key'],
            aws_secret_access_key=config['secret']
        )

        # Lister tous les backups
        paginator = s3_client.get_paginator('list_objects_v2')
        pages = paginator.paginate(Bucket=config['bucket'], Prefix='backups/database/')

        deleted_count = 0
        for page in pages:
            if 'Contents' not in page:
                continue

            for obj in page['Contents']:
                # VÃ©rifier la date de modification
                if obj['LastModified'].replace(tzinfo=None) < cutoff_date:
                    s3_client.delete_object(Bucket=config['bucket'], Key=obj['Key'])
                    deleted_count += 1
                    print(f"  ğŸ—‘ï¸  SupprimÃ©: {obj['Key']}")

        if deleted_count > 0:
            print(f"âœ… {deleted_count} ancien(s) backup(s) supprimÃ©(s)")
        else:
            print(f"âœ… Aucun backup Ã  supprimer")

    except Exception as e:
        print(f"âš ï¸  Erreur lors du nettoyage: {e}")

def main():
    """Fonction principale."""
    print("=" * 70)
    print("ğŸš€ BACKUP AUTOMATIQUE BASE DE DONNÃ‰ES ATLAS")
    print(f"ğŸ“… Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 70)
    print()

    # 1. CrÃ©er le backup SQL
    backup_path = create_database_backup()
    if not backup_path:
        print("\nâŒ Ã‰chec du backup")
        sys.exit(1)

    # 2. Compresser
    compressed_path = compress_backup(backup_path)
    if not compressed_path:
        print("\nâŒ Ã‰chec de la compression")
        sys.exit(1)

    # 3. Upload vers Spaces
    spaces_key = upload_to_spaces(compressed_path)
    if not spaces_key:
        print("\nâŒ Ã‰chec de l'upload")
        sys.exit(1)

    # 4. Nettoyer les vieux backups
    cleanup_old_backups()

    print()
    print("=" * 70)
    print("âœ… BACKUP TERMINÃ‰ AVEC SUCCÃˆS")
    print(f"ğŸ“‚ Fichier: {spaces_key}")
    print("=" * 70)

if __name__ == '__main__':
    main()
