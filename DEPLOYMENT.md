# ğŸš€ Guide de DÃ©ploiement - Plateforme Patrimoine

## ğŸ“‹ Vue d'ensemble

Ce document dÃ©crit comment dÃ©ployer la plateforme de gestion de patrimoine en production.

## ğŸ”§ DÃ©ploiement Local (DÃ©veloppement)

### MÃ©thode Rapide
```bash
# Navigation vers le projet
cd "Jepargne digital"

# Lancement automatique
python3 start_app.py
```

### MÃ©thode Manuelle
```bash
# Installation des dÃ©pendances
pip3 install -r requirements.txt

# Lancement
python3 run.py
```

## â˜ï¸ DÃ©ploiement Production

### Option 1 : Heroku
```bash
# Installation Heroku CLI
brew install heroku/brew/heroku

# Connexion
heroku login

# CrÃ©ation de l'app
heroku create patrimoine-pro

# Configuration des variables
heroku config:set SECRET_KEY="your-super-secret-key"
heroku config:set FLASK_ENV="production"

# Ajout de PostgreSQL
heroku addons:create heroku-postgresql:hobby-dev

# DÃ©ploiement
git add .
git commit -m "Deploy to production"
git push heroku main
```

### Option 2 : DigitalOcean Droplet
```bash
# Connexion au serveur
ssh root@your-server-ip

# Installation Python et pip
apt update
apt install python3 python3-pip nginx

# Clone du projet
git clone https://github.com/your-repo/patrimoine-pro.git
cd patrimoine-pro

# Installation des dÃ©pendances
pip3 install -r requirements.txt

# Configuration Gunicorn
pip3 install gunicorn

# Lancement
gunicorn -w 4 -b 0.0.0.0:8000 run:app
```

### Option 3 : Docker
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 5000

CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "run:app"]
```

```bash
# Construction et lancement
docker build -t patrimoine-pro .
docker run -p 5000:5000 patrimoine-pro
```

## ğŸ—„ï¸ Configuration Base de DonnÃ©es

### SQLite (DÃ©veloppement)
```python
# app/__init__.py
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///patrimoine.db'
```

### PostgreSQL (Production)
```python
# app/__init__.py
app.config['SQLALCHEMY_DATABASE_URI'] = os.environ.get('DATABASE_URL')
```

```bash
# Variables d'environnement
export DATABASE_URL="postgresql://user:password@localhost/patrimoine_db"
```

## ğŸ” Variables d'Environnement

### Fichier .env
```bash
# SÃ©curitÃ©
SECRET_KEY=your-super-secret-key-very-long-and-complex
FLASK_ENV=production

# Base de donnÃ©es
DATABASE_URL=postgresql://user:password@localhost/patrimoine_db

# OpenAI (pour l'assistant IA)
OPENAI_API_KEY=your-openai-api-key

# Email (pour notifications futures)
MAIL_SERVER=smtp.gmail.com
MAIL_PORT=587
MAIL_USERNAME=your-email@gmail.com
MAIL_PASSWORD=your-email-password

# Stripe (pour paiements futures)
STRIPE_PUBLIC_KEY=pk_test_...
STRIPE_SECRET_KEY=sk_test_...
```

## ğŸŒ Configuration Nginx

```nginx
# /etc/nginx/sites-available/patrimoine-pro
server {
    listen 80;
    server_name your-domain.com;

    location / {
        proxy_pass http://127.0.0.1:5000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /static {
        alias /path/to/your/app/static;
    }
}
```

## ğŸ”’ SSL/HTTPS avec Let's Encrypt

```bash
# Installation Certbot
apt install certbot python3-certbot-nginx

# Obtention du certificat
certbot --nginx -d your-domain.com

# Renouvellement automatique
crontab -e
# Ajouter : 0 12 * * * /usr/bin/certbot renew --quiet
```

## ğŸ“Š Monitoring et Logs

### Logs Application
```python
# app/__init__.py
import logging
from logging.handlers import RotatingFileHandler

if app.config['FLASK_ENV'] == 'production':
    file_handler = RotatingFileHandler('logs/patrimoine.log', maxBytes=10240, backupCount=10)
    file_handler.setFormatter(logging.Formatter(
        '%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'
    ))
    file_handler.setLevel(logging.INFO)
    app.logger.addHandler(file_handler)
    app.logger.setLevel(logging.INFO)
```

### Monitoring avec Supervisor
```ini
# /etc/supervisor/conf.d/patrimoine-pro.conf
[program:patrimoine-pro]
command=gunicorn -w 4 -b 127.0.0.1:5000 run:app
directory=/path/to/your/app
user=www-data
autostart=true
autorestart=true
redirect_stderr=true
stdout_logfile=/var/log/patrimoine-pro.log
```

## ğŸš€ Script de DÃ©ploiement Automatique

```bash
#!/bin/bash
# deploy.sh

echo "ğŸš€ DÃ©ploiement de la Plateforme Patrimoine"

# Sauvegarde de la base de donnÃ©es
echo "ğŸ“ Sauvegarde de la base de donnÃ©es..."
pg_dump patrimoine_db > backup_$(date +%Y%m%d_%H%M%S).sql

# ArrÃªt de l'application
echo "â¹ï¸ ArrÃªt de l'application..."
supervisorctl stop patrimoine-pro

# Mise Ã  jour du code
echo "ğŸ“¥ Mise Ã  jour du code..."
git pull origin main

# Installation des nouvelles dÃ©pendances
echo "ğŸ“¦ Installation des dÃ©pendances..."
pip3 install -r requirements.txt

# Migration de la base de donnÃ©es
echo "ğŸ—„ï¸ Migration de la base de donnÃ©es..."
python3 -c "from app import create_app, db; app = create_app(); app.app_context().push(); db.create_all()"

# RedÃ©marrage de l'application
echo "ğŸ”„ RedÃ©marrage de l'application..."
supervisorctl start patrimoine-pro

# VÃ©rification du statut
echo "âœ… VÃ©rification du statut..."
curl -f http://localhost:5000 && echo "DÃ©ploiement rÃ©ussi !" || echo "Erreur de dÃ©ploiement !"
```

## ğŸ”„ Sauvegarde et Restauration

### Sauvegarde automatique
```bash
#!/bin/bash
# backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/var/backups/patrimoine-pro"

# CrÃ©ation du dossier de sauvegarde
mkdir -p $BACKUP_DIR

# Sauvegarde de la base de donnÃ©es
pg_dump patrimoine_db > $BACKUP_DIR/db_$DATE.sql

# Sauvegarde des fichiers uploadÃ©s
tar -czf $BACKUP_DIR/uploads_$DATE.tar.gz app/static/uploads/

# Nettoyage des anciennes sauvegardes (> 30 jours)
find $BACKUP_DIR -name "*.sql" -mtime +30 -delete
find $BACKUP_DIR -name "*.tar.gz" -mtime +30 -delete

echo "Sauvegarde terminÃ©e : $DATE"
```

### Cron pour sauvegardes automatiques
```bash
# crontab -e
# Sauvegarde quotidienne Ã  2h du matin
0 2 * * * /path/to/backup.sh
```

## ğŸ“ˆ Optimisations Performance

### Gunicorn optimisÃ©
```bash
# Configuration recommandÃ©e
gunicorn -w 4 \
         --max-requests 1000 \
         --max-requests-jitter 50 \
         --timeout 120 \
         --keep-alive 5 \
         -b 0.0.0.0:5000 \
         run:app
```

### Redis pour cache (optionnel)
```bash
# Installation Redis
apt install redis-server

# Configuration Flask
pip3 install Flask-Caching redis
```

```python
# app/__init__.py
from flask_caching import Cache

cache = Cache()
cache.init_app(app, config={'CACHE_TYPE': 'redis'})
```

## ğŸ” Tests de Performance

```bash
# Test de charge avec Apache Bench
ab -n 1000 -c 10 http://your-domain.com/

# Monitoring avec htop
htop

# VÃ©rification des logs
tail -f /var/log/patrimoine-pro.log
```

## ğŸª™ Configuration Cryptomonnaies - OBLIGATOIRE

### âš ï¸ IMPORTANT - Scheduler IntÃ©grÃ© DÃ©sactivÃ©

Le scheduler Flask intÃ©grÃ© a Ã©tÃ© **DÃ‰SACTIVÃ‰** pour Ã©viter les appels API en boucle qui causaient des lenteurs.

**Configuration actuelle :**
- âœ… Scheduler intÃ©grÃ© : **DÃ‰SACTIVÃ‰**
- âœ… Script externe : `refresh_crypto_prices.py`
- âš ï¸ Cron : **Ã€ CONFIGURER EN PRODUCTION**
- âœ… API locale : `/api/crypto-prices` (lecture DB uniquement)

### Configuration CRON Obligatoire

```bash
# Se connecter au serveur
crontab -e

# Ajouter cette ligne pour mise Ã  jour des prix crypto toutes les heures :
0 * * * * cd /path/to/your/atlas/app && python refresh_crypto_prices.py >> ../logs/crypto_refresh.log 2>&1

# Alternative : toutes les 30 minutes pour plus de prÃ©cision
*/30 * * * * cd /path/to/your/atlas/app && python refresh_crypto_prices.py >> ../logs/crypto_refresh.log 2>&1

# CrÃ©er le dossier logs si nÃ©cessaire
mkdir -p /path/to/your/atlas/logs
```

### Test de la Configuration Crypto

```bash
# Test manuel du script
cd /path/to/your/atlas/app
python refresh_crypto_prices.py

# VÃ©rifier les logs
tail -f logs/crypto_refresh.log

# VÃ©rifier que l'API fonctionne (doit Ãªtre ultra-rapide)
curl -X POST http://localhost:5000/api/crypto-prices \
  -H "Content-Type: application/json" \
  -d '{"symbols": ["btc", "eth"]}'
```

### Performance Crypto

- âŒ **Avant** : 2-3 minutes (200+ appels API Binance)
- âœ… **Maintenant** : < 1 seconde (lecture DB locale)

### Monitoring Crypto

```bash
# VÃ©rifier la derniÃ¨re mise Ã  jour des prix
# (dans votre interface DB ou avec un script)
SELECT symbol, price_eur, last_updated 
FROM crypto_prices 
ORDER BY last_updated DESC 
LIMIT 10;

# Alerter si pas de mise Ã  jour depuis plus de 2h
*/15 * * * * /path/to/check_crypto_freshness.sh
```

## âš ï¸ Checklist PrÃ©-Production

- [ ] Variables d'environnement configurÃ©es
- [ ] Base de donnÃ©es PostgreSQL prÃªte
- [ ] **CRON crypto configurÃ© et testÃ©**
- [ ] **API crypto locale fonctionnelle**
- [ ] **Scheduler Flask intÃ©grÃ© DÃ‰SACTIVÃ‰**
- [ ] SSL/HTTPS activÃ©
- [ ] Sauvegardes automatiques configurÃ©es
- [ ] Monitoring en place
- [ ] Tests de performance effectuÃ©s
- [ ] Documentation Ã  jour
- [ ] ClÃ©s API configurÃ©es (OpenAI, Stripe)
- [ ] Emails de notification configurÃ©s

## ğŸš¨ Points Critiques Post-DÃ©ploiement

1. **VÃ©rifier immÃ©diatement** que le CRON crypto fonctionne
2. **Tester la performance** de la page donnÃ©es investisseur (doit Ãªtre < 2s)
3. **Surveiller les logs** crypto les premiÃ¨res 24h
4. **Alerter** si Ã©chec refresh crypto > 2h consÃ©cutives

---

**ğŸš€ Votre plateforme est maintenant prÃªte pour la production !**

**ğŸ’¡ N'oubliez pas de configurer le CRON crypto dÃ¨s le premier dÃ©ploiement !**